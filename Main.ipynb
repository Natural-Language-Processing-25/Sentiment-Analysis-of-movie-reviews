{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1595eb27",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e1aabd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You may need to run those in your enviroment terminal.\n",
    "\n",
    "# pip install numpy==1.24.3 pandas==1.5.3\n",
    "# pip install spacy\n",
    "# pip install \"thinc<8.3.6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b6641483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Rahma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Rahma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a5438",
   "metadata": {},
   "source": [
    "Creating data frame of the data and assigning them labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "06d524bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>if anything , \" stigmata \" should be taken as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>john boorman's \" zardoz \" is a goofy cinematic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0</td>\n",
       "      <td>the kids in the hall are an acquired taste . \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>there was a time when john carpenter was a gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>two party guys bob their heads to haddaway's d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "1995      0  if anything , \" stigmata \" should be taken as ...\n",
       "1996      0  john boorman's \" zardoz \" is a goofy cinematic...\n",
       "1997      0  the kids in the hall are an acquired taste . \\...\n",
       "1998      0  there was a time when john carpenter was a gre...\n",
       "1999      0  two party guys bob their heads to haddaway's d..."
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "\n",
    "base_path = Path('review_polarity/txt_sentoken')\n",
    "pos_path = base_path / 'pos'\n",
    "neg_path = base_path / 'neg'\n",
    "\n",
    "# Assign label 1\n",
    "if pos_path.exists():\n",
    "    for file in pos_path.glob('*.txt'):\n",
    "        with open(file, 'r', encoding = 'utf-8') as f:\n",
    "            texts.append(f.read())\n",
    "            labels.append(1)\n",
    "\n",
    "# Assign label 0\n",
    "if neg_path.exists():\n",
    "    for file in neg_path.glob('*.txt'):\n",
    "        with open(file, 'r', encoding = 'utf-8') as f:\n",
    "            texts.append(f.read())\n",
    "            labels.append(0)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'label': labels,\n",
    "    'text': texts\n",
    "})\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ad59ad76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c1716a",
   "metadata": {},
   "source": [
    "No duplicates were found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c6d84703-7454-4dd4-b1c8-9a4d5b6d5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_pos_to_wordnet_pos(spacy_pos):\n",
    "    if spacy_pos.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif spacy_pos.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif spacy_pos.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif spacy_pos.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b8f35a43-5c47-49ad-8cc6-95ffa03211cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    synonyms.discard(word)      # Remove the original word to avoid replacement with itself\n",
    "    return list(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "161f45fe-6246-4ff3-895c-85d4092ca01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_text_with_synonyms(tokens, pos_tags, synonym_probability = 0.2):\n",
    "    augmented_tokens = []\n",
    "    \n",
    "    for token, pos_tag in zip(tokens, pos_tags):\n",
    "        if random.random() < synonym_probability:\n",
    "            if pos_tag in ['n', 'v', 'a']:   #nouns adjectives and verbs \n",
    "                synonyms = get_synonyms(token)\n",
    "                if synonyms:\n",
    "                    new_word = random.choice(synonyms)\n",
    "                    augmented_tokens.append(new_word)\n",
    "                    continue  \n",
    "        augmented_tokens.append(token)         # Add the original word if no augmentation is done\n",
    "    \n",
    "    return augmented_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "33efe070-6a00-4518-b544-7ee483699d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_augmentation_to_dataset(word_tokens, pos_tags, texts, labels, sentence_tokens, synonym_probability = 0.2):\n",
    "    all_word_tokens = word_tokens.copy()\n",
    "    all_texts = texts.copy()  # Original text is preserved\n",
    "    all_labels = labels.copy()\n",
    "    all_sentence_tokens = sentence_tokens.copy()\n",
    "    all_pos_tags = pos_tags.copy()\n",
    "\n",
    "    for tokens, pos, label, sentence, text in zip(word_tokens, pos_tags, labels, sentence_tokens, texts):\n",
    "        augmented_tokens = augment_text_with_synonyms(tokens, pos, synonym_probability)\n",
    "\n",
    "        all_word_tokens.append(augmented_tokens)\n",
    "        all_texts.append(text)  # Keep the original text\n",
    "        all_labels.append(label)\n",
    "        all_pos_tags.append(pos)\n",
    "        all_sentence_tokens.append(sentence)  # Sentence tokens are not augmented\n",
    "\n",
    "    return all_word_tokens, all_pos_tags, all_texts, all_labels, all_sentence_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f4aac42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lemmatization(tokens):\n",
    "    return [token.lemma_ for token in nlp(' '.join(tokens))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c3d4bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(text):\n",
    "    \n",
    "    words = text.split()\n",
    "    return ' '.join([PorterStemmer().stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "695072c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tf_idf_heatmap(tfidf_matrix, feature_names, n_top_features = 20, n_top_docs = 10):\n",
    "    # Get the top features by summing TF-IDF scores across documents\n",
    "    tfidf_array = tfidf_matrix.toarray()\n",
    "    feature_importance = np.sum(tfidf_array, axis = 0)\n",
    "    top_feature_indices = np.argsort(feature_importance)[-n_top_features:][::-1]\n",
    "    top_features = [feature_names[i] for i in top_feature_indices]\n",
    "    \n",
    "    # Get the top documents by summing TF-IDF scores across features\n",
    "    doc_importance = np.sum(tfidf_array, axis=1)\n",
    "    top_doc_indices = np.argsort(doc_importance)[-n_top_docs:][::-1]\n",
    "    \n",
    "    # Extract the submatrix for visualization\n",
    "    sub_matrix = tfidf_array[np.ix_(top_doc_indices, top_feature_indices)]\n",
    "    \n",
    "    plt.figure(figsize = (12, 8))\n",
    "    sns.heatmap(\n",
    "        sub_matrix,\n",
    "        annot = True,          # Show values in cells\n",
    "        fmt = '.3f',           # Format with 3 decimal places\n",
    "        cmap = 'YlGnBu',       # Better colormap\n",
    "        xticklabels = top_features,\n",
    "        yticklabels = range(n_top_docs)\n",
    "    )\n",
    "    plt.title(f'TF-IDF Heatmap (Top {n_top_features} Features, First {n_top_docs} Documents)')\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Documents')\n",
    "    plt.xticks(rotation = 45, ha = 'right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('tfidf_heatmap.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Bar chart of top features across the corpus\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_features_scores = [feature_importance[i] for i in top_feature_indices]\n",
    "    plt.bar(top_features, top_features_scores)\n",
    "    plt.title('Top TF-IDF Features Across All Documents')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Sum of TF-IDF Scores')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('tfidf_top_features.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7bd110ab-6e79-481b-9108-ac484b4acd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Matrix Shape: (4000, 42977)\n",
      "Number of features: 42977\n"
     ]
    }
   ],
   "source": [
    "texts = df['text'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "word_tokens = []\n",
    "sentence_tokens = []\n",
    "pos_tags = []\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    sentence_tokens.append([sent.text.strip() for sent in doc.sents])\n",
    "    tokens = [token for token in doc if not token.is_punct and not token.is_stop and not token.is_space]\n",
    "    word_tokens.append([token.text.lower() for token in tokens])\n",
    "    pos_tags.append([spacy_pos_to_wordnet_pos(token.tag_) for token in tokens])\n",
    "\n",
    "lemmatized_tokens = [apply_lemmatization(t) for t in word_tokens]\n",
    "\n",
    "word_tokens, pos_tags, texts, labels, sentence_tokens = apply_augmentation_to_dataset(\n",
    "    lemmatized_tokens, pos_tags, texts, labels, sentence_tokens\n",
    ")\n",
    "\n",
    "joined_texts = [' '.join(tokens) for tokens in word_tokens]\n",
    "\n",
    "augmented_df = pd.DataFrame({\n",
    "    'label': labels,\n",
    "    'text': joined_texts,\n",
    "    'word_tokens': word_tokens\n",
    "})\n",
    "\n",
    "augmented_df = augmented_df.sample(frac = 1, random_state = 42).reset_index(drop = True)\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    augmented_df['text'], augmented_df['label'], test_size = 0.2, random_state = 42\n",
    ")\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(train_texts)\n",
    "xtrain_tfidf = vectorizer.transform(train_texts)\n",
    "xtest_tfidf = vectorizer.transform(test_texts)\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(joined_texts)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"\\nTF-IDF Matrix Shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Number of features: {len(feature_names)}\")\n",
    "visualize_tf_idf_heatmap(tfidf_matrix, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "05795c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_df.head():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>word_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>harmless silly fun comedy dim witted wrestling...</td>\n",
       "      <td>[harmless, silly, fun, comedy, dim, witted, wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>point movie shit opera go completely wrong mem...</td>\n",
       "      <td>[point, movie, shit, opera, go, completely, wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>sick life death bob flanagan supermasochist fe...</td>\n",
       "      <td>[sick, life, death, bob, flanagan, supermasoch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>everybody film believe alicia documentary see ...</td>\n",
       "      <td>[everybody, film, believe, alicia, documentary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>lisa cholodenko high art intelligent quiet pla...</td>\n",
       "      <td>[lisa, cholodenko, high, art, intelligent, qui...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  harmless silly fun comedy dim witted wrestling...   \n",
       "1      0  point movie shit opera go completely wrong mem...   \n",
       "2      1  sick life death bob flanagan supermasochist fe...   \n",
       "3      0  everybody film believe alicia documentary see ...   \n",
       "4      1  lisa cholodenko high art intelligent quiet pla...   \n",
       "\n",
       "                                         word_tokens  \n",
       "0  [harmless, silly, fun, comedy, dim, witted, wr...  \n",
       "1  [point, movie, shit, opera, go, completely, wr...  \n",
       "2  [sick, life, death, bob, flanagan, supermasoch...  \n",
       "3  [everybody, film, believe, alicia, documentary...  \n",
       "4  [lisa, cholodenko, high, art, intelligent, qui...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df.head():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>every now and then a movie comes along from a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>you've got mail works alot better than it dese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\" jaws \" is a rare film that grabs your atten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>moviemaking is a lot like being the general ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  films adapted from comic books have had plenty...\n",
       "1      1  every now and then a movie comes along from a ...\n",
       "2      1  you've got mail works alot better than it dese...\n",
       "3      1   \" jaws \" is a rare film that grabs your atten...\n",
       "4      1  moviemaking is a lot like being the general ma..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"augmented_df.head():\")\n",
    "display(augmented_df.head())\n",
    "\n",
    "print(\"\\ndf.head():\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6fe295e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_df.tail():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>word_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0</td>\n",
       "      <td>understand clich hell earth truly mean recentl...</td>\n",
       "      <td>[understand, clich, hell, earth, truly, mean, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0</td>\n",
       "      <td>1954 japanese monster film godzilla transform ...</td>\n",
       "      <td>[1954, japanese, monster, film, godzilla, tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>1</td>\n",
       "      <td>verdict spine chill drama horror maestro steph...</td>\n",
       "      <td>[verdict, spine, chill, drama, horror, maestro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0</td>\n",
       "      <td>midway anaconda documentary filmmaker terri fl...</td>\n",
       "      <td>[midway, anaconda, documentary, filmmaker, ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0</td>\n",
       "      <td>starship trooper bad movie mean bad movie cros...</td>\n",
       "      <td>[starship, trooper, bad, movie, mean, bad, mov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "3995      0  understand clich hell earth truly mean recentl...   \n",
       "3996      0  1954 japanese monster film godzilla transform ...   \n",
       "3997      1  verdict spine chill drama horror maestro steph...   \n",
       "3998      0  midway anaconda documentary filmmaker terri fl...   \n",
       "3999      0  starship trooper bad movie mean bad movie cros...   \n",
       "\n",
       "                                            word_tokens  \n",
       "3995  [understand, clich, hell, earth, truly, mean, ...  \n",
       "3996  [1954, japanese, monster, film, godzilla, tran...  \n",
       "3997  [verdict, spine, chill, drama, horror, maestro...  \n",
       "3998  [midway, anaconda, documentary, filmmaker, ter...  \n",
       "3999  [starship, trooper, bad, movie, mean, bad, mov...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df.tail():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>if anything , \" stigmata \" should be taken as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>john boorman's \" zardoz \" is a goofy cinematic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0</td>\n",
       "      <td>the kids in the hall are an acquired taste . \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>there was a time when john carpenter was a gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>two party guys bob their heads to haddaway's d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "1995      0  if anything , \" stigmata \" should be taken as ...\n",
       "1996      0  john boorman's \" zardoz \" is a goofy cinematic...\n",
       "1997      0  the kids in the hall are an acquired taste . \\...\n",
       "1998      0  there was a time when john carpenter was a gre...\n",
       "1999      0  two party guys bob their heads to haddaway's d..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"augmented_df.tail():\")\n",
    "display(augmented_df.tail())\n",
    "\n",
    "print(\"\\ndf.tail():\")\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "039b47bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df dimentions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "augmented_df dimentions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\ndf dimentions:\")\n",
    "display(df.shape)\n",
    "\n",
    "print(\"\\naugmented_df dimentions:\")\n",
    "display(augmented_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67965868",
   "metadata": {},
   "source": [
    "# Modelling - Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a699ea3",
   "metadata": {},
   "source": [
    "####        •    ML -> Logistic Regression, Naive Bayes, SVM, Decision tree, and Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d3f41270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, train_labels, feature_vector_test, test_labels, is_neural_net=False):\n",
    "    classifier.fit(feature_vector_train, train_labels)\n",
    "    \n",
    "    train_predictions = classifier.predict(feature_vector_train)\n",
    "    test_predictions = classifier.predict(feature_vector_test)\n",
    "    train_accuracy = metrics.accuracy_score(train_labels, train_predictions)\n",
    "    test_accuracy = metrics.accuracy_score(test_labels, test_predictions)\n",
    "    \n",
    "    print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f9d515",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2711bfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 98.19%\n",
      "Test Accuracy: 92.62%\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_labels, xtest_tfidf, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c00af1b",
   "metadata": {},
   "source": [
    "#### 2. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f6801ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 99.88%\n",
      "Test Accuracy: 93.38%\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(naive_bayes.MultinomialNB(alpha = 0.0001), xtrain_tfidf, train_labels, xtest_tfidf,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1b670",
   "metadata": {},
   "source": [
    "#### 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1e74a87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 99.59%\n",
      "Test Accuracy: 95.62%\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(svm.SVC(kernel = 'linear', C = 1.0), xtrain_tfidf, train_labels, xtest_tfidf, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4f9d0071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 99.94%\n",
      "Test Accuracy: 96.62%\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(svm.SVC(kernel = 'rbf', C = 1.0), xtrain_tfidf, train_labels, xtest_tfidf, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6a3eefc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 100.00%\n",
      "Test Accuracy: 93.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(svm.SVC(kernel = 'poly', C = 1.0, degree = 3), xtrain_tfidf, train_labels, xtest_tfidf, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e209c",
   "metadata": {},
   "source": [
    "#### 4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "067e770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 100.00%\n",
      "Test Accuracy: 79.38%\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(DecisionTreeClassifier(), xtrain_tfidf, train_labels, xtest_tfidf, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7281ccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 100.00%\n",
      "Test Accuracy: 94.12%\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(RandomForestClassifier(), xtrain_tfidf, train_labels, xtest_tfidf, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe38d91",
   "metadata": {},
   "source": [
    "#### • DL -> BERT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
